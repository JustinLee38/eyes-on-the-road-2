{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8189ccca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class_activation_map(model, img):\n",
    "    ''' \n",
    "    this function computes the class activation map\n",
    "    \n",
    "    Inputs:\n",
    "        1) model (tensorflow model) : trained model\n",
    "        2) img (numpy array of shape (224, 224, 3)) : input image\n",
    "    '''\n",
    "    \n",
    "    # expand dimension to fit the image to a network accepted input size\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "\n",
    "    # predict to get the winning class\n",
    "    predictions = model.predict(img)\n",
    "    label_index = np.argmax(predictions)\n",
    "\n",
    "    # Get the 2048 input weights to the softmax of the winning class.\n",
    "    class_weights = model.layers[-1].get_weights()[0]\n",
    "    class_weights_winner = class_weights[:, label_index]\n",
    "    \n",
    "    # get the final conv layer\n",
    "    final_conv_layer = model.get_layer(\"conv5_block3_out\")\n",
    "    \n",
    "    # create a function to fetch the final conv layer output maps (should be shape (1, 7, 7, 2048)) \n",
    "    get_output = K.function([model.layers[0].input],[final_conv_layer.output, model.layers[-1].output])\n",
    "    [conv_outputs, predictions] = get_output([img])\n",
    "    \n",
    "    # squeeze conv map to shape image to size (7, 7, 2048)\n",
    "    conv_outputs = np.squeeze(conv_outputs)\n",
    "    \n",
    "    # bilinear upsampling to resize each filtered image to size of original image \n",
    "    mat_for_mult = scipy.ndimage.zoom(conv_outputs, (32, 32, 1), order=1) # dim: 224 x 224 x 2048\n",
    "\n",
    "    # get class activation map for object class that is predicted to be in the image\n",
    "    final_output = np.dot(mat_for_mult.reshape((224*224, 2048)), class_weights_winner).reshape(224,224) # dim: 224 x 224\n",
    "    \n",
    "    # return class activation map\n",
    "    return final_output, label_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8bbf10da",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def get_model():\n",
    "\t    model = VGG16_convolutions()\n",
    "\t    model = load_model_weights(model, \"vgg16_weights.h5\")\n",
    "\t    \n",
    "\t    model.add(Lambda(global_average_pooling, \n",
    "\t              output_shape=global_average_pooling_shape))\n",
    "\t    model.add(Dense(2, activation = 'softmax', init='uniform'))\n",
    "\t    sgd = SGD(lr=0.01, decay=1e-6, momentum=0.5, nesterov=True)\n",
    "\t    model.compile(loss = 'categorical_crossentropy', \\\n",
    "            optimizer = sgd, metrics=['accuracy'])\n",
    "\t    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21d3a664",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def visualize_class_activation_map(model_path, img_path, output_path):\n",
    "        model = load_model(model_path)\n",
    "        original_img = cv2.imread(img_path, 1)\n",
    "        width, height, _ = original_img.shape\n",
    "\n",
    "        #Reshape to the network input shape (3, w, h).\n",
    "        img = np.array([np.transpose(np.float32(original_img), (2, 0, 1))])\n",
    "        \n",
    "        #Get the 512 input weights to the softmax.\n",
    "        class_weights = model.layers[-1].get_weights()[0]\n",
    "        final_conv_layer = get_output_layer(model, \"conv5_3\")\n",
    "        get_output = K.function([model.layers[0].input], \\\n",
    "                    [final_conv_layer.output, \n",
    "        model.layers[-1].output])\n",
    "        [conv_outputs, predictions] = get_output([img])\n",
    "        conv_outputs = conv_outputs[0, :, :, :]\n",
    "\n",
    "        #Create the class activation map.\n",
    "        cam = np.zeros(dtype = np.float32, shape = conv_outputs.shape[1:3])\n",
    "        target_class = 1\n",
    "        for i, w in enumerate(class_weights[:, target_class]):\n",
    "                cam += w * conv_outputs[i, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e2fb885",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
